{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad55bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.utils.utils import secret_from_env\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import Field, SecretStr\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b42fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatOpenRouter(ChatOpenAI):\n",
    "    openai_api_key: Optional[SecretStr] = Field(\n",
    "        alias=\"api_key\",\n",
    "        default_factory=secret_from_env(\"OPENROUTER_API_KEY\", default=None),\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def lc_secrets(self) -> dict[str, str]:\n",
    "        return {\"openai_api_key\": \"OPENROUTER_API_KEY\"}\n",
    "\n",
    "    def __init__(self, openai_api_key: Optional[str] = None, **kwargs):\n",
    "        openai_api_key = openai_api_key or os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "        super().__init__(base_url=\"https://openrouter.ai/api/v1\",\n",
    "                         openai_api_key=openai_api_key,\n",
    "                         **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "238d609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openrouter_model = ChatOpenRouter(\n",
    "    model_name=\"meituan/longcat-flash-chat:free\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa9c9349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm Sonoma, built by Oak AI. What's on your mind today?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openrouter_model.invoke(\"Hello, world!\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99211cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = openrouter_model.invoke(\"Can you speak Chinese?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc76f7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f27a0f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æ˜¯çš„ï¼Œæˆ‘å¯ä»¥è¯´ä¸­æ–‡ï¼æˆ‘æ˜¯Sonomaï¼Œç”±Oak AIæž„å»ºçš„AIåŠ©æ‰‹ï¼Œèƒ½ç”¨ä¸­æ–‡æµåˆ©äº¤æµã€‚ä½ æœ‰ä»€ä¹ˆé—®é¢˜æˆ–æƒ³èŠä»€ä¹ˆå—ï¼Ÿ'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b35964e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æ˜¯çš„ï¼Œæˆ‘å¯ä»¥è¯´ä¸­æ–‡ï¼æˆ‘æ˜¯Sonomaï¼Œç”±Oak AIæž„å»ºçš„AIåŠ©æ‰‹ï¼Œèƒ½ç”¨ä¸­æ–‡æµåˆ©äº¤æµã€‚ä½ æœ‰ä»€ä¹ˆé—®é¢˜æˆ–æƒ³èŠä»€ä¹ˆå—ï¼Ÿ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 34, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'openrouter/sonoma-dusk-alpha', 'system_fingerprint': None, 'id': 'gen-1757597371-Fhy6beyYfoBtbRDOaXwL', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--8bd621fb-f88d-4681-aa9e-eac011365a92-0', usage_metadata={'input_tokens': 34, 'output_tokens': 30, 'total_tokens': 64, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfcb1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1cde8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I can speak Chinese. For example: ä½ å¥½ï¼æˆ‘æ˜¯Sonomaï¼Œç”±Oak AIæž„å»ºçš„AIåŠ©æ‰‹ã€‚å¦‚æžœä½ æœ‰é—®é¢˜ï¼Œç”¨ä¸­æ–‡é—®æˆ‘ä¹Ÿæ²¡é—®é¢˜ã€‚'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = openrouter_model | StrOutputParser()\n",
    "chain.invoke(\"Can you speak Chinese?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "297e05d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // ç”¨æˆ·çš„å§“å\n",
      "\t\"age\": string  // ç”¨æˆ·çš„å¹´é¾„\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"ç”¨æˆ·çš„å§“å\"),\n",
    "    ResponseSchema(name=\"age\", description=\"ç”¨æˆ·çš„å¹´é¾„\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "881cc143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'å¼ ä¸‰', 'age': '20'}\n"
     ]
    }
   ],
   "source": [
    "from string import printable\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"å›žç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¹¶è¿”å›žJsonæ ¼å¼ï¼š{question}\\n{format_instructions}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "chain = prompt | openrouter_model | parser\n",
    "res = chain.invoke({\"question\": \"æˆ‘çš„åå­—å«å¼ ä¸‰ï¼Œæˆ‘ä»Šå¹´20å²ã€‚\"})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961622c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello, how are you?' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "message = HumanMessage(content=\"Hello, how are you?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2706f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Here's a classic one for you:  \\n\\n**Why don't eggs tell jokes?**  \\nBecause they crack up!  \\n\\n(If you want a groaner, here's another: **What do you call a fake noodle?** An *impasta*! ðŸ˜†)  \\n\\nWant a specific type of joke? Iâ€™ve got plenty! ðŸŽ¤\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 15, 'total_tokens': 92, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meituan/longcat-flash-chat:free', 'system_fingerprint': None, 'id': 'gen-1759646538-yAMXNP6KIgs3sGUSCZQm', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--01f2d57a-e16a-4091-9870-a3d5522cb234-0', usage_metadata={'input_tokens': 15, 'output_tokens': 77, 'total_tokens': 92, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = openrouter_model.invoke([HumanMessage(\"Tell me a joke\")])\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5199f36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'refusal': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38056131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 77,\n",
       "  'prompt_tokens': 15,\n",
       "  'total_tokens': 92,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_tokens_details': None},\n",
       " 'model_name': 'meituan/longcat-flash-chat:free',\n",
       " 'system_fingerprint': None,\n",
       " 'id': 'gen-1759646538-yAMXNP6KIgs3sGUSCZQm',\n",
       " 'service_tier': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\"\n",
    "for chunk in openrouter_model.stream([HumanMessage(\"what color is the sky?\")]):\n",
    "    res += chunk.content\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2549ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResponseFormatter(BaseModel):\n",
    "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
    "    answer: str = Field(description=\"The answer to the user's question\")\n",
    "    followup_question: str = Field(description=\"A followup question the user could ask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64d15429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = openrouter_model.bind_tools([ResponseFormatter])\n",
    "# Invoke the model\n",
    "ai_msg = model_with_tools.invoke(\"What is the powerhouse of the cell?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7d14616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'ResponseFormatter',\n",
       "  'args': {'answer': \"The powerhouse of the cell is the mitochondria. It generates most of the cell's supply of adenosine triphosphate (ATP), used as a source of chemical energy.\",\n",
       "   'followup_question': 'Would you like to learn more about the structure and functions of mitochondria?'},\n",
       "  'id': 'call_4877bc5c23e6418b964956ef',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b86b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the dictionary into a pydantic object\n",
    "pydantic_object = ResponseFormatter.model_validate(ai_msg.tool_calls[0][\"args\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf28aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenRouter(\n",
    "    model_name=\"meituan/longcat-flash-chat:free\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4fc70fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_ints': [12, 45, 67, 23, 89, 34, 56, 78, 91, 3]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.with_structured_output(method=\"json_mode\")\n",
    "ai_msg = model.invoke(\"Return a JSON object with key 'random_ints' and a value of 10 random ints in [0-99]\")\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5a86982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFormatter(answer=\"The powerhouse of the cell is the mitochondria. It generates most of the cell's supply of adenosine triphosphate (ATP), which is used as a source of chemical energy.\", followup_question='What is the function of the mitochondria in the cell?')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bind the schema to the model\n",
    "model_with_structure = model.with_structured_output(ResponseFormatter)\n",
    "# Invoke the model\n",
    "structured_output = model_with_structure.invoke(\"What is the powerhouse of the cell?\")\n",
    "# Get back the pydantic object\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3eddeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "   r\"\"\"Multiply two numbers.\"\"\"\n",
    "   return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a19633bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\": 2, \"b\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7844f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name) # multiply\n",
    "print(multiply.description) # Multiply two numbers.\n",
    "print(multiply.args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8056252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def generate_random_ints(min: int, max: int, size: int) -> Tuple[str, List[int]]:\n",
    "    \"\"\"Generate size random ints in the range [min, max].\"\"\"\n",
    "    array = [random.randint(min, max) for _ in range(size)]\n",
    "    content = f\"Successfully generated array of {size} random ints in [{min}, {max}].\"\n",
    "    return content, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c73db797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully generated array of 10 random ints in [0, 9].'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke({\"min\": 0, \"max\": 9, \"size\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdfe9cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Successfully generated array of 10 random ints in [0, 9].', name='generate_random_ints', tool_call_id='123', artifact=[2, 5, 2, 5, 6, 3, 1, 7, 3, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke(\n",
    "    {\n",
    "        \"name\": \"generate_random_ints\",\n",
    "        \"args\": {\"min\": 0, \"max\": 9, \"size\": 10},\n",
    "        \"id\": \"123\",  # required\n",
    "        \"type\": \"tool_call\",  # required\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f8d6e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_79bf979d0eb1456db4552f51', 'function': {'arguments': '{\"min\": 1, \"max\": 24, \"size\": 6}', 'name': 'generate_random_ints'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 147, 'total_tokens': 182, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meituan/longcat-flash-chat:free', 'system_fingerprint': None, 'id': 'gen-1759673930-E4we9tHd2hNhBNDe0CMS', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--eac1fc61-1c30-4e80-aef9-0c3d45fa509a-0', tool_calls=[{'name': 'generate_random_ints', 'args': {'min': 1, 'max': 24, 'size': 6}, 'id': 'call_79bf979d0eb1456db4552f51', 'type': 'tool_call'}], usage_metadata={'input_tokens': 147, 'output_tokens': 35, 'total_tokens': 182, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenRouter(\n",
    "    model_name=\"meituan/longcat-flash-chat:free\"\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([generate_random_ints])\n",
    "ai_msg = llm_with_tools.invoke(\"generate 6 positive ints less than 25\")\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b940536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'generate_random_ints',\n",
       "  'args': {'min': 1, 'max': 24, 'size': 6},\n",
       "  'id': 'call_79bf979d0eb1456db4552f51',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f452f3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Successfully generated array of 6 random ints in [1, 24].', name='generate_random_ints', tool_call_id='call_79bf979d0eb1456db4552f51', artifact=[13, 3, 22, 4, 8, 15])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke(ai_msg.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8be825ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully generated array of 6 random ints in [1, 24].'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke(ai_msg.tool_calls[0][\"args\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "798e2a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='Successfully generated array of 1 random ints in [1, 5].', name='generate_random_ints', tool_call_id='call_2e0ed180644942cfb541aa12', artifact=[4])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "\n",
    "chain = llm_with_tools | attrgetter(\"tool_calls\") | generate_random_ints.map()\n",
    "\n",
    "chain.invoke(\"give me a random number between 1 and 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40afd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56ed987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['msgs'], input_types={'msgs': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001F48D2FFF40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='msgs')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
